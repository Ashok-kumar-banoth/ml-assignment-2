{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 1: Install Gensim\n",
        "!pip install gensim --quiet\n",
        "\n",
        "# ✅ STEP 2: Import Libraries (no nltk this time!)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import gensim.downloader as api\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "\n",
        "# ✅ STEP 3: Preprocessing Without NLTK\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)         # Remove punctuation\n",
        "    words = text.split()                         # Tokenize\n",
        "    words = [word for word in words if word not in ENGLISH_STOP_WORDS]\n",
        "    return words\n",
        "\n",
        "# ✅ STEP 4: Load Word2Vec\n",
        "w2v_model = api.load(\"word2vec-google-news-300\")  # ⏳ loads 1.5 GB\n",
        "\n",
        "# ✅ STEP 5: Vectorize function\n",
        "def vectorize_message(msg, model):\n",
        "    words = preprocess_text(msg)\n",
        "    word_vectors = [model[word] for word in words if word in model]\n",
        "    return np.mean(word_vectors, axis=0) if word_vectors else np.zeros(300)\n",
        "\n",
        "# ✅ STEP 6: Load spam.csv (already uploaded)\n",
        "df = pd.read_csv('spam.csv', encoding='latin-1')[['v1', 'v2']]\n",
        "df.columns = ['Label', 'Message']\n",
        "\n",
        "# ✅ STEP 7: Vectorize Messages\n",
        "df['vector'] = df['Message'].apply(lambda x: vectorize_message(x, w2v_model))\n",
        "\n",
        "# ✅ STEP 8: Prepare Training and Testing Data\n",
        "X = np.vstack(df['vector'].values)\n",
        "y = df['Label'].map({'ham': 0, 'spam': 1})\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ✅ STEP 9: Train Model\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# ✅ STEP 10: Evaluate\n",
        "print(\"✅ Spam Classification Accuracy:\", round(accuracy_score(y_test, clf.predict(X_test)) * 100, 2), \"%\")\n",
        "\n",
        "# ✅ STEP 11: Prediction Function\n",
        "def predict_message_class(message):\n",
        "    vec = vectorize_message(message, w2v_model).reshape(1, -1)\n",
        "    return 'spam' if clf.predict(vec)[0] == 1 else 'ham'\n",
        "\n",
        "# ✅ STEP 12: Try Example Predictions\n",
        "print(\"Example 1:\", predict_message_class(\"Congratulations! You have won a free iPhone. Click here to claim.\"))\n",
        "print(\"Example 2:\", predict_message_class(\"Hi, let's catch up tomorrow after class.\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxuMJ07g3da3",
        "outputId": "c1a7c127-25a6-488c-e787-8da9ae8daf5a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Spam Classification Accuracy: 94.35 %\n",
            "Example 1: spam\n",
            "Example 2: ham\n"
          ]
        }
      ]
    }
  ]
}